{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DMA3_V_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LbFunnkEfGPH",
        "w6OQEmMUfGPO"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem fomulation"
      ],
      "metadata": {
        "id": "q7aAatbW_d5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we have some posts some of them are fake and some are real on raddit and as we know fake news has caused many social problems due to the raise of social network and its role in different domains such as politics. we are going to predict if a specific reddit post is fake news or not, by looking at its title. The data is raw has data in form of text which need to be preproccessed and extract feature from which are the posts (input) and a labels which represents the probability that this post will be fake( output).\n",
        "Data mining function required is prediction.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   What could be the challenges? Coverting raw data into useful features ‚ö†\n",
        "*   What is the impact? We will be able to prevent many social problems caused by fake news üöë\n",
        "\n",
        "-What is an ideal solution? ‚úå\n",
        "The ideal model is svm using embeddeding with word-ngram but with very high time complexity while logistic is less performance but takes less time complexity\n",
        "\n",
        "Note: \n",
        "The questions and answers and the optimal solution are at the end of the notebook\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dN-j8A8MPEl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing tools üé®"
      ],
      "metadata": {
        "id": "DLWYnWVn_jKu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "az9GZX1_CjiA"
      },
      "outputs": [],
      "source": [
        "#Preparing our tools\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading Files ‚úç"
      ],
      "metadata": {
        "id": "9gUNI_S__mJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading our dataset\n",
        "data = pd.read_csv(\"/xy_train.csv\")  #Reading our train set \n",
        "data1 = pd.read_csv(\"/x_test.csv\")   #Reading our test set\n",
        "data #printing our train set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "b0eTU6hmCzni",
        "outputId": "69ef799e-f958-49ea-f6b4-1f60676399b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                               text  label\n",
              "0      265723  A group of friends began to volunteer at a hom...      0\n",
              "1      284269  British Prime Minister @Theresa_May on Nerve A...      0\n",
              "2      207715  In 1961, Goodyear released a kit that allows P...      0\n",
              "3      551106  Happy Birthday, Bob Barker! The Price Is Right...      0\n",
              "4        8584  Obama to Nation: ËÅô\"Innocent Cops and Unarmed Y...      0\n",
              "...       ...                                                ...    ...\n",
              "59995   70046  Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion o...      0\n",
              "59996  189377  Nigerian Prince Scam took $110K from Kansas ma...      1\n",
              "59997   93486  Is It Safe To Smoke Marijuana During Pregnancy...      0\n",
              "59998  140950  Julius Caesar upon realizing that everyone in ...      0\n",
              "59999   34509  Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New...      1\n",
              "\n",
              "[60000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c09718ba-f801-42c2-96ff-77911dfdc918\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>265723</td>\n",
              "      <td>A group of friends began to volunteer at a hom...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284269</td>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve A...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207715</td>\n",
              "      <td>In 1961, Goodyear released a kit that allows P...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>551106</td>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8584</td>\n",
              "      <td>Obama to Nation: ËÅô\"Innocent Cops and Unarmed Y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>70046</td>\n",
              "      <td>Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>189377</td>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>93486</td>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>140950</td>\n",
              "      <td>Julius Caesar upon realizing that everyone in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>34509</td>\n",
              "      <td>Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c09718ba-f801-42c2-96ff-77911dfdc918')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c09718ba-f801-42c2-96ff-77911dfdc918 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c09718ba-f801-42c2-96ff-77911dfdc918');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop row that has label 2\n",
        "\n",
        "data = data[data.label != 2]"
      ],
      "metadata": {
        "id": "rh0s8Mi1UMkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving our ids in idfor later use\n",
        "id=data1.id\n",
        "id"
      ],
      "metadata": {
        "id": "a_oufhrNLxtN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c25030b-5404-4373-b374-69c1187e2e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            0\n",
              "1            1\n",
              "2            2\n",
              "3            3\n",
              "4            4\n",
              "         ...  \n",
              "59146    59146\n",
              "59147    59147\n",
              "59148    59148\n",
              "59149    59149\n",
              "59150    59150\n",
              "Name: id, Length: 59151, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping id as it doesnt give us any useful information\n",
        "data.drop(columns=['id'],axis='columns', inplace=True)\n",
        "data1.drop(columns=['id'],axis='columns', inplace=True)"
      ],
      "metadata": {
        "id": "PQeQ_nSRXZj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432ac6e4-12eb-4239-ffd8-e8f8594c5dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text cleaning and processing steps-\n",
        "\n",
        "\n",
        "*   Remove punctuations\n",
        "*   Convert text to tokens\n",
        "\n",
        "*   Remove stopwords using NLTK corpus stopwords list to match\n",
        "*   Apply stemming\n",
        "\n",
        "*   Convert words to feature vectors\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ip1jFjnHAR9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing some tools for word preprocessing \n",
        "import re\n",
        "import pickle\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import holoviews as hv\n",
        "import nltk \n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# some seeting for pandas and hvplot\n",
        "\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 300\n",
        "pd.options.display.max_colwidth = 100\n",
        "np.set_printoptions(threshold=2000)"
      ],
      "metadata": {
        "id": "2i-ICvfPfEyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing more tools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "A8CdrVeZfJuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "#Choosing the steemmer language english\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stop_words = set(stopwords.words(\"english\")) #stopwords\n",
        "\n",
        "\n",
        "def clean_text(text, for_embedding=False):\n",
        "    \"\"\" steps:\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "    \"\"\"\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-z√Ä-≈æ ]\", re.IGNORECASE)\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z√Ä-≈æ]\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        RE_ASCII = re.compile(r\"[^A-Za-z√Ä-≈æ,.!? ]\", re.IGNORECASE)\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z√Ä-≈æ,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text)\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    if for_embedding:\n",
        "        # no stemming, lowering and punctuation / stop words removal\n",
        "        words_filtered = word_tokens\n",
        "    else:\n",
        "        words_filtered = [\n",
        "# Apply stemming to convert tokens to their root form. This is a rule-based process of word form conversion where word-suffixes are truncated irrespective of whether the root word is an actual word in the language dictionary.\n",
        "        \n",
        "            stemmer.stem(word) for word in words_tokens_lower if word not in stop_words \n",
        "            \n",
        "            ]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGkDNlZxg37B",
        "outputId": "33499300-8a5f-404c-cbf6-b0529929bd30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean texts for train dataset\n",
        "data[\"text_clean\"] = data.loc[data[\"text\"].str.len() > 20, \"text\"]\n",
        "data[\"text_clean\"] = data[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x, for_embedding=False) if isinstance(x, str) else x\n",
        ")\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "id": "Wg6GctLFg5yI",
        "outputId": "9a4c9159-16b8-4d28-8cd9-884f5ab6baa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                      text  \\\n",
              "0      A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1      British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2      In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3      Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4      Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                    ...   \n",
              "59995                Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion of Finland by the USSR (1939, colorized)   \n",
              "59996                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "59997                Is It Safe To Smoke Marijuana During Pregnancy? YouÈà•Ê™á Be Surprised Of The Answer | no   \n",
              "59998                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "59999                Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "       label  \\\n",
              "0          0   \n",
              "1          0   \n",
              "2          0   \n",
              "3          0   \n",
              "4          0   \n",
              "...      ...   \n",
              "59995      0   \n",
              "59996      1   \n",
              "59997      0   \n",
              "59998      0   \n",
              "59999      1   \n",
              "\n",
              "                                                                                                text_clean  \n",
              "0      group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...  \n",
              "1      british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...  \n",
              "2      goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...  \n",
              "3      happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...  \n",
              "4      obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...  \n",
              "...                                                                                                    ...  \n",
              "59995                                                       finish sniper simo yh invas finland ussr color  \n",
              "59996                                               nigerian princ scam took kansa man year later get back  \n",
              "59997                                                         safe smoke marijuana pregnanc surpris answer  \n",
              "59998                                               julius caesar upon realiz everyon room knife except bc  \n",
              "59999                                        jeff bridg releas leep tape new album design help fall asleep  \n",
              "\n",
              "[59768 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9feee01-36e1-45f0-a016-e4c780c04102\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "      <td>group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "      <td>british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "      <td>goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "      <td>obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "      <td>finish sniper simo yh invas finland ussr color</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "      <td>nigerian princ scam took kansa man year later get back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? YouÈà•Ê™á Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "      <td>safe smoke marijuana pregnanc surpris answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "      <td>julius caesar upon realiz everyon room knife except bc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "      <td>jeff bridg releas leep tape new album design help fall asleep</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59768 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9feee01-36e1-45f0-a016-e4c780c04102')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9feee01-36e1-45f0-a016-e4c780c04102 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9feee01-36e1-45f0-a016-e4c780c04102');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Clean texts for test data\n",
        "data1[\"text_clean\"] = data1.loc[data1[\"text\"].str.len() > 0, \"text\"]\n",
        "data1[\"text_clean\"] = data1[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x, for_embedding=False) if isinstance(x, str) else x\n",
        ")\n",
        "data1"
      ],
      "metadata": {
        "id": "OZmUW3fYA-1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "07176395-dbe0-4497-e14b-750c34ae973a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                  text  \\\n",
              "0                                                                           stargazer    \n",
              "1                                                                                 yeah   \n",
              "2                           PD: Phoenix car thief gets instructions from YouTube video   \n",
              "3                       As Trump Accuses Iran, He Has One Problem: His Own Credibility   \n",
              "4                                                         \"Believers\" - Hezbollah 2011   \n",
              "...                                                                                ...   \n",
              "59146                                                Bicycle taxi drivers of New Delhi   \n",
              "59147                             Trump blows up GOP's formula for winning House races   \n",
              "59148  Napoleon returns from his exile on the island of Elba. (March 1815), Colourised   \n",
              "59149                                 Deep down he always wanted to be a ballet dancer   \n",
              "59150                        Toddler miraculously survives 6-story fall landing on car   \n",
              "\n",
              "                                            text_clean  \n",
              "0                                              stargaz  \n",
              "1                                                 yeah  \n",
              "2       pd phoenix car thief get instruct youtub video  \n",
              "3                 trump accus iran one problem credibl  \n",
              "4                                     believ hezbollah  \n",
              "...                                                ...  \n",
              "59146                     bicycl taxi driver new delhi  \n",
              "59147             trump blow gop formula win hous race  \n",
              "59148  napoleon return exil island elba march colouris  \n",
              "59149                    deep alway want ballet dancer  \n",
              "59150       toddler miracul surviv stori fall land car  \n",
              "\n",
              "[59151 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bfb8f87f-396e-4848-8feb-f75032362305\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stargazer</td>\n",
              "      <td>stargaz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yeah</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "      <td>pd phoenix car thief get instruct youtub video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
              "      <td>trump accus iran one problem credibl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "      <td>believ hezbollah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "      <td>bicycl taxi driver new delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>Trump blows up GOP's formula for winning House races</td>\n",
              "      <td>trump blow gop formula win hous race</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>Napoleon returns from his exile on the island of Elba. (March 1815), Colourised</td>\n",
              "      <td>napoleon return exil island elba march colouris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "      <td>deep alway want ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>Toddler miraculously survives 6-story fall landing on car</td>\n",
              "      <td>toddler miracul surviv stori fall land car</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfb8f87f-396e-4848-8feb-f75032362305')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bfb8f87f-396e-4848-8feb-f75032362305 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bfb8f87f-396e-4848-8feb-f75032362305');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop when any of x missing\n",
        "data = data[(data[\"text_clean\"] != \"\") & (data[\"text_clean\"] != \"null\")]\n",
        "\n",
        "data = data.dropna(axis=\"index\", ).reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "grh-AD3-DnN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "nQGH1N2pQOW2",
        "outputId": "f404e285-d239-45ae-ec7f-b43721a2166e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                      text  \\\n",
              "0      A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1      British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2      In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3      Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4      Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                    ...   \n",
              "59753                Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion of Finland by the USSR (1939, colorized)   \n",
              "59754                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "59755                Is It Safe To Smoke Marijuana During Pregnancy? YouÈà•Ê™á Be Surprised Of The Answer | no   \n",
              "59756                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "59757                Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "       label  \\\n",
              "0          0   \n",
              "1          0   \n",
              "2          0   \n",
              "3          0   \n",
              "4          0   \n",
              "...      ...   \n",
              "59753      0   \n",
              "59754      1   \n",
              "59755      0   \n",
              "59756      0   \n",
              "59757      1   \n",
              "\n",
              "                                                                                                text_clean  \n",
              "0      group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...  \n",
              "1      british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...  \n",
              "2      goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...  \n",
              "3      happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...  \n",
              "4      obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...  \n",
              "...                                                                                                    ...  \n",
              "59753                                                       finish sniper simo yh invas finland ussr color  \n",
              "59754                                               nigerian princ scam took kansa man year later get back  \n",
              "59755                                                         safe smoke marijuana pregnanc surpris answer  \n",
              "59756                                               julius caesar upon realiz everyon room knife except bc  \n",
              "59757                                        jeff bridg releas leep tape new album design help fall asleep  \n",
              "\n",
              "[59758 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28820403-276c-432d-950a-8a106e249a01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "      <td>group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "      <td>british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "      <td>goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "      <td>obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59753</th>\n",
              "      <td>Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "      <td>finish sniper simo yh invas finland ussr color</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59754</th>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "      <td>nigerian princ scam took kansa man year later get back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59755</th>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? YouÈà•Ê™á Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "      <td>safe smoke marijuana pregnanc surpris answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59756</th>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "      <td>julius caesar upon realiz everyon room knife except bc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59757</th>\n",
              "      <td>Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "      <td>jeff bridg releas leep tape new album design help fall asleep</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59758 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28820403-276c-432d-950a-8a106e249a01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28820403-276c-432d-950a-8a106e249a01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28820403-276c-432d-950a-8a106e249a01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "HqeIAcBZQRIm",
        "outputId": "27b68831-8f1c-4a51-ea57-e9b314440d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                  text  \\\n",
              "0                                                                           stargazer    \n",
              "1                                                                                 yeah   \n",
              "2                           PD: Phoenix car thief gets instructions from YouTube video   \n",
              "3                       As Trump Accuses Iran, He Has One Problem: His Own Credibility   \n",
              "4                                                         \"Believers\" - Hezbollah 2011   \n",
              "...                                                                                ...   \n",
              "59146                                                Bicycle taxi drivers of New Delhi   \n",
              "59147                             Trump blows up GOP's formula for winning House races   \n",
              "59148  Napoleon returns from his exile on the island of Elba. (March 1815), Colourised   \n",
              "59149                                 Deep down he always wanted to be a ballet dancer   \n",
              "59150                        Toddler miraculously survives 6-story fall landing on car   \n",
              "\n",
              "                                            text_clean  \n",
              "0                                              stargaz  \n",
              "1                                                 yeah  \n",
              "2       pd phoenix car thief get instruct youtub video  \n",
              "3                 trump accus iran one problem credibl  \n",
              "4                                     believ hezbollah  \n",
              "...                                                ...  \n",
              "59146                     bicycl taxi driver new delhi  \n",
              "59147             trump blow gop formula win hous race  \n",
              "59148  napoleon return exil island elba march colouris  \n",
              "59149                    deep alway want ballet dancer  \n",
              "59150       toddler miracul surviv stori fall land car  \n",
              "\n",
              "[59151 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e68b1b58-1e93-46fb-890f-a759522a40e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stargazer</td>\n",
              "      <td>stargaz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yeah</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "      <td>pd phoenix car thief get instruct youtub video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
              "      <td>trump accus iran one problem credibl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "      <td>believ hezbollah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "      <td>bicycl taxi driver new delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>Trump blows up GOP's formula for winning House races</td>\n",
              "      <td>trump blow gop formula win hous race</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>Napoleon returns from his exile on the island of Elba. (March 1815), Colourised</td>\n",
              "      <td>napoleon return exil island elba march colouris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "      <td>deep alway want ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>Toddler miraculously survives 6-story fall landing on car</td>\n",
              "      <td>toddler miracul surviv stori fall land car</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e68b1b58-1e93-46fb-890f-a759522a40e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e68b1b58-1e93-46fb-890f-a759522a40e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e68b1b58-1e93-46fb-890f-a759522a40e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA7fo5vWfGPF"
      },
      "source": [
        "For our classification task, we want to be able to recognize whether a post has is fake or real. We make use of the label that come alongside with all texts. *Naturally, zero represents real and 1 represents the existanse of fake posts . We need to predict the probabality of being fake"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbFunnkEfGPH"
      },
      "source": [
        "### Descriptive analysis\n",
        "\n",
        "Even though we deal with texts, we should still use some descriptive analysis to get a better understanding of the data:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.models import NumeralTickFormatter\n",
        "# Word Frequency of most common words\n",
        "word_freq = pd.Series(\" \".join(data[\"text_clean\"]).split()).value_counts()\n",
        "word_freq[1:40]\n",
        "len(word_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4SU7vqTBr61",
        "outputId": "4a4d495a-b183-4fbf-b4c5-a96e8f46eec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40373"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I3PiezJfGPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8dd378a-5bcf-4c65-b1ae-632f7d8d0745"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      index  freq\n",
              "0   angriff     1\n",
              "1  delusion     1\n",
              "2      wane     1\n",
              "3  undament     1\n",
              "4      miku     1\n",
              "5    hatsun     1\n",
              "6     nfler     1\n",
              "7    hicock     1\n",
              "8    mccall     1\n",
              "9      wahr     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b86ca35c-6a93-4a4e-a24f-178781a26725\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>angriff</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>delusion</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wane</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>undament</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>miku</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>hatsun</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>nfler</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>hicock</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>mccall</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>wahr</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b86ca35c-6a93-4a4e-a24f-178781a26725')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b86ca35c-6a93-4a4e-a24f-178781a26725 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b86ca35c-6a93-4a4e-a24f-178781a26725');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# list most uncommon words\n",
        "word_freq[-10:].reset_index(name=\"freq\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature creation with TF-IDF\n",
        "Because classification models cannot deal with text data directly, we need to convert our comments to a numeric representation. As mentioned before, there are several ways to achieve this. This article provides a concise overview. All methods have in common that they assign each unique word in a document a unique number. A vector of numbers is created in which each element represents a word. Logically, the length of the vector will equal the number of unique words. In the simplest form (bag of words), a sentence can be represented by such a vector by indicating the presence of a word using a 1 in the appropriate index representing the word. All elements standing for words not included in the sentence will be 0.\n",
        "Frequency methods improve on this very basic approach. For many applications, TF-IDF (term frequency, inverse document frequency) is a good choice. In our case, the TF part summarizes how often a word appears in a comment in relation to all words. As was mentioned earlier, that is not always a sufficient indicator for a useful word as it might be overly general or be used inflationary in many comments. This is where the IDF part comes into play. It downscales words that are prevalent in many other comments. Consequently, words that are frequent in a comment and also specific to it (i.e. they are uncommon in other comments) will get a high weight. Unspecific words or those with a low overall frequency will get a low weight.\n",
        "This is how we apply TF-IDF to our comments using scikit-learn:"
      ],
      "metadata": {
        "id": "UmKDRMWgEFiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Compute unique word vector with frequencies\n",
        "exclude very uncommon (<10 obsv.) and common (>=30%) words\n",
        "use pairs of two words (ngram)\n",
        "\"\"\"\n",
        "vectorizer = TfidfVectorizer(\n",
        "    analyzer=\"word\", max_df=0.3, min_df=10, ngram_range=(1, 2), norm=\"l2\"\n",
        ")\n",
        "vectorizer.fit(data[\"text_clean\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWj3VN6DCXrH",
        "outputId": "3c165fc1-e4d5-41a9-dcaf-3dceb7c5dd8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(max_df=0.3, min_df=10, ngram_range=(1, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector representation of vocabulary\n",
        "word_vector = pd.Series(vectorizer.vocabulary_).sample(5, random_state=1)\n",
        "print(f\"Unique word (ngram) vector extract:\\n\\n {word_vector}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QWCyl11EUS8",
        "outputId": "e19f0bf9-2338-4c7c-d8ef-6208c3af11dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique word (ngram) vector extract:\n",
            "\n",
            " eli       2666\n",
            "go far    3595\n",
            "bamboo     650\n",
            "wisdom    9837\n",
            "pocket    6705\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking missing values\n",
        "def missing_values(data1):\n",
        "    missing=pd.DataFrame(data1.isnull().sum()/len(data1))*100\n",
        "    missing.columns = ['missing_values(%)']\n",
        "    missing['missing_values(numbers)'] = pd.DataFrame(data1.isnull().sum())\n",
        "    return missing.sort_values(by='missing_values(%)', ascending=False)\n",
        "missing_values(data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "LjfEkU1cTRs1",
        "outputId": "c8e577a9-55e1-4608-d935-57a3c6bc37bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            missing_values(%)  missing_values(numbers)\n",
              "text                      0.0                        0\n",
              "text_clean                0.0                        0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a958471b-b97f-4e05-8f51-1e079658ecf8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missing_values(%)</th>\n",
              "      <th>missing_values(numbers)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_clean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a958471b-b97f-4e05-8f51-1e079658ecf8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a958471b-b97f-4e05-8f51-1e079658ecf8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a958471b-b97f-4e05-8f51-1e079658ecf8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling\n",
        "To test the classification performance of our model, we will perform a cross validation. For that, we split our data into a training and a testing set. The former is used to train the model and the latter to evaluate its predictions:"
      ],
      "metadata": {
        "id": "buA5ROlAFHTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting X train and y actual and X test\n",
        "\n",
        "X_train = data[\"text_clean\"]\n",
        "Y_train = data[\"label\"]\n",
        "X_test = data1[\"text_clean\"]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XdYle7IEc7t",
        "outputId": "bb26dd13-c55f-48be-8c8c-c44a5c66f797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(59758,)\n",
            "(59151,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # transform each sentence to numeric vector with tf-idf value as elements\n",
        "# X_train_vec = vectorizer.transform(X_train)\n",
        "# #X_test_vec = vectorizer.transform(X_test)\n",
        "# X_train_vec.get_shape()"
      ],
      "metadata": {
        "id": "kxfHBtRLFvl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Compare original comment text with its numeric vector representation\n",
        "# print(f\"Original sentence:\\n{X_train[3:4].values}\\n\")\n",
        "# # Feature Matrix\n",
        "# features = pd.DataFrame(\n",
        "#     X_train_vec[3:4].toarray(), columns=vectorizer.get_feature_names()\n",
        "# )\n",
        "# nonempty_feat = features.loc[:, (features != 0).any(axis=0)]\n",
        "# print(f\"Vector representation of sentence:\\n {nonempty_feat}\")"
      ],
      "metadata": {
        "id": "0Xyihla7GGDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyOyXy1ufGPL"
      },
      "source": [
        "For this five word sentence, the vector of length 4107 contains mostly zeros. However, the indices representing the used words / ngrams are non empty. They include the value that `TF-IDF` assigned to them. In this particular case, \"arzt empfehl\" (recommend doctor) has the largest weight meaning that it is relatively frequent in our sentence while not being very common in other sentences of our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6RlcKebfGPL"
      },
      "source": [
        "Now, that we have prepared our features, we can start to train and evaluate models. For a binary classification task there are many options to [chose from in `scikit-learn`](https://scikit-learn.org/stable/supervised_learning.html). We will focus on the ones that are most promising. In my experience they are: Logistic Regression, Support Vector Classification (SVC), Ensemble Methods (Boosting, Random Forest) and Neural Networks (i.e. Multi Layer Perceptron or MLP in sklearn). We will compare these models and chose the most promising one:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# models to test\n",
        "classifiers = [\n",
        "    LogisticRegression(solver=\"sag\", random_state=1),\n",
        "    LinearSVC(random_state=1),\n",
        "    RandomForestClassifier(random_state=1),\n",
        "    XGBClassifier(random_state=1),\n",
        "    MLPClassifier(\n",
        "        random_state=1,\n",
        "        solver=\"adam\",\n",
        "        hidden_layer_sizes=(12, 12, 12),\n",
        "        activation=\"relu\",\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=1,\n",
        "    ),\n",
        "]\n",
        "# get names of the objects in list (too lazy for c&p...)\n",
        "names = [re.match(r\"[^\\(]+\", name.__str__())[0] for name in classifiers]\n",
        "print(f\"Classifiers to test: {names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqPdTGM6GJbd",
        "outputId": "addf75a0-8540-415b-df27-4b4e84633d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifiers to test: ['LogisticRegression', 'LinearSVC', 'RandomForestClassifier', 'XGBClassifier', 'MLPClassifier']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6OQEmMUfGPO"
      },
      "source": [
        "### Parameter tuning\n",
        "WE will try tuning different models to find the optimal midel with the best parameterd\n",
        "We've learned that linear SVC is a solid model choice and delivers great results out of the box. Still, we might be able to improve upon those by taking a more guided approach to choosing parameters. To do so, we will compare different parameters for feature creation as well as modeling. We can achieve this by making use of the pipeline and grid search functionality in sci-kit learn and random search"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "In statistics, the logistic model is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick. This can be extended to model several classes of events such as determining whether an image contains a cat, dog, lion, etc\n",
        "It is used in statistical software to understand the relationship between the dependent variable and one or more independent variables by estimating probabilities using a logistic regression equation. This type of analysis can help you predict the likelihood of an event happening or a choice being made."
      ],
      "metadata": {
        "id": "R2WEsI97Gqb9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "95c74797-2943-466f-e80c-9d43bae8f1dd",
        "id": "ZXrCqbUYymFT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                       ('svc', LogisticRegression())]),\n",
              "             n_jobs=2,\n",
              "             param_grid={'tfidf__max_df': array([0.3]),\n",
              "                         'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                         'tfidf__ngram_range': [(1, 2), (1, 3)]},\n",
              "             scoring='roc_auc')"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# feature creation and modelling in a single function\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "pipe = Pipeline(\n",
        "    [\n",
        "                 (\"tfidf\", TfidfVectorizer()), \n",
        "                 (\"log\", LogisticRegression())])\n",
        "                 \n",
        "\n",
        "# define parameter space to test # runtime 3hrs\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "   \n",
        "}\n",
        "# it is quite slow so we do 4 for now\n",
        "pipe_clf =GridSearchCV(\n",
        "    pipe, params, n_jobs=2, scoring=\"roc_auc\", cv=4)\n",
        "pipe_clf.fit(X_train, Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vN5g85iqH_ZV",
        "outputId": "807f280b-0a1e-47b2-d807-6826ff996750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'tfidf__max_df': 0.3, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n"
          ]
        }
      ],
      "source": [
        "print(pipe_clf.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zW3JQKvxymFa"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = id\n",
        "\n",
        "submission['label'] = pipe_clf.predict_proba(data1['text_clean'])[:,1]\n",
        "\n",
        "submission.to_csv('Log.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AyzcFu7ymFa"
      },
      "source": [
        "Score: 0.83893\n",
        "Public score: 0.83739"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost classifier"
      ],
      "metadata": {
        "id": "OGJPkT9br6rq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "190fb810-1cc8-452c-a5b5-70ef9e770050",
        "id": "__hg26Ody8So"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[03:02:27] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "pipe = Pipeline(\n",
        "    [\n",
        "                 (\"tfidf\", TfidfVectorizer()), \n",
        "                 (\"XGC\", XGBClassifier())])\n",
        "                 \n",
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "     \n",
        "    # preprocessor__num__imputer__strategy points to preprocessor->num (a Pipeline)-> imputer -> strategy\n",
        "    'XGC__n_estimators': [200, 300, 400],  \n",
        "     # my_classifier__n_estimators points to my_classifier->n_estimators \n",
        "    'XGC__max_depth':[8,9,10,11]     \n",
        "    \n",
        "}\n",
        "# it is quite slow so we do 4 for now\n",
        "pipe_clf = RandomizedSearchCV(\n",
        "    pipe, params, n_jobs=2, scoring=\"roc_auc\", n_iter=3)\n",
        "pipe_clf.fit(X_train, Y_train)\n",
        "pickle.dump(pipe_clf, open(\"./clf_pipe.pck\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpiyROoKmTFI",
        "outputId": "07b6686e-0575-4743-c373-68b290cdc90a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 30, 'tfidf__max_df': 0.3, 'XGC__n_estimators': 400, 'XGC__max_depth': 8}\n"
          ]
        }
      ],
      "source": [
        "print(pipe_clf.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ncnkf0uey8Sw"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = id\n",
        "\n",
        "submission['label'] = pipe_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('LOG_.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz-ndecby8Sw"
      },
      "source": [
        "0.71131 \n",
        "### ‚òπ\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *From our observation we can find out that grid search is not the right choice for hypertuning our parameters as we have a very large data set which will require more computational time and power so random search will be more suitable and as well ysing a predifined split and compare between different models*"
      ],
      "metadata": {
        "id": "pe3hGKRBs0NC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predefined split"
      ],
      "metadata": {
        "id": "eg1MNlBpUufD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "\n",
        "\n",
        "# Further split the original training set to a train and a validation set\n",
        "X_train2, X_val, y_train2, y_val = train_test_split(\n",
        "    X_train, Y_train, train_size = 0.7, stratify = Y_train, random_state = 3800)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in X_train2.index else 0 for x in X_train.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1aFyFKOjT00R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a pipline for logistics regression\n",
        "pipe = Pipeline(\n",
        "    [\n",
        "                 (\"tfidf\", TfidfVectorizer()), \n",
        "                 (\"svc\", LogisticRegression())])\n",
        "                 \n",
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "    #  'svc__n_estimators': [20, 30, 40],  \n",
        "    #  my_classifier__n_estimators points to my_classifier->n_estimators \n",
        "    'svc__penalty':['none', 'l1', 'l2', 'elasticnet']  ,    \n",
        "    'svc__solver' :['newton-cg', 'lbfgs', 'liblinear'],\n",
        "    'svc__C' :  [1e-5, 100]\n",
        "}\n",
        "pipe_clf1 =RandomizedSearchCV(\n",
        "    pipe, params, n_jobs=2, scoring=\"roc_auc\", cv=pds, n_iter=4)\n",
        "pipe_clf1.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuBhKw8QU76o",
        "outputId": "2262c8a8-fd26-4eea-f38f-480b9947c001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "1 fits failed out of a total of 4.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.8534813  0.8473583  0.85205756        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                             ('svc', LogisticRegression())]),\n",
              "                   n_iter=4, n_jobs=2,\n",
              "                   param_distributions={'svc__C': [1e-05, 100],\n",
              "                                        'svc__penalty': ['none', 'l1', 'l2',\n",
              "                                                         'elasticnet'],\n",
              "                                        'svc__solver': ['newton-cg', 'lbfgs',\n",
              "                                                        'liblinear'],\n",
              "                                        'tfidf__max_df': array([0.3]),\n",
              "                                        'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        'tfidf__ngram_range': [(1, 2), (1, 3)]},\n",
              "                   scoring='roc_auc')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = id\n",
        "\n",
        "submission['label'] = pipe_clf1.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('LOG1_.csv', index=False)"
      ],
      "metadata": {
        "id": "_9KrTj8LW-gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.81254\n",
        "Public score: 0.81070"
      ],
      "metadata": {
        "id": "4da7IliCYkKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *From my observations, I have found that Logistic Regression would be very effective on text data and the underlying algorithm is also fairly easy to understand. More importantly, in the NLP world, it's generally accepted that Logistic Regression is a great starter algorithm for text related classification and reduire less computaional time which makes it more effective.*"
      ],
      "metadata": {
        "id": "v40JjkFMtbFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline(\n",
        "    [\n",
        "                 (\"tfidf\", TfidfVectorizer()), \n",
        "                 (\"XGC\", XGBClassifier())])\n",
        "                 \n",
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "     \n",
        "    # preprocessor__num__imputer__strategy points to preprocessor->num (a Pipeline)-> imputer -> strategy\n",
        "    'XGC__n_estimators': [200, 300, 400],  \n",
        "     # my_classifier__n_estimators points to my_classifier->n_estimators \n",
        "    'XGC__max_depth':[8,9,10,11]     \n",
        "    \n",
        "}\n",
        "pipe_clf2 =RandomizedSearchCV(\n",
        "    pipe, params, n_jobs=2, scoring=\"roc_auc\", cv=pds, n_iter=4)\n",
        "pipe_clf2.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ANn4CLFWAh4",
        "outputId": "08c1e24e-b72b-49cf-dd35-74983d44f78a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                             ('XGC', XGBClassifier())]),\n",
              "                   n_iter=4, n_jobs=2,\n",
              "                   param_distributions={'XGC__max_depth': [8, 9, 10, 11],\n",
              "                                        'XGC__n_estimators': [200, 300, 400],\n",
              "                                        'tfidf__max_df': array([0.3]),\n",
              "                                        'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        'tfidf__ngram_range': [(1, 2), (1, 3)]},\n",
              "                   scoring='roc_auc')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = id\n",
        "\n",
        "submission['label'] = pipe_clf2.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('XG1_.csv', index=False)"
      ],
      "metadata": {
        "id": "HhosNQzJWAye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.80544\n",
        "Public score: 0.80636"
      ],
      "metadata": {
        "id": "jeeA64MqbyDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *We can see that didn't perform well. We can conclud that XGBoost does not perform so well on sparse and unstructured data. A common thing often forgotten is that Gradient Boosting is very sensitive to outliers since every classifier is forced to fix the errors in the predecessor learners. The overall method is hardly scalable.*"
      ],
      "metadata": {
        "id": "l6euVYJbvAs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear spport vector machine"
      ],
      "metadata": {
        "id": "IM1zju3DvaPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"svc\", SVC(class_weight='balanced', kernel='linear',probability=True,))])\n",
        "\n",
        "# define parameter space to test # runtime 19min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 3)],\n",
        "    \"tfidf__max_df\": [0.5],\n",
        "    \"tfidf__min_df\": [5],\n",
        "    \"svc__C\": np.arange(0.2, 1, 0.15),\n",
        "}\n",
        "pipe_svc_clf = RandomizedSearchCV(pipe, params, n_jobs=2, scoring=\"roc_auc\",  cv=pds, n_iter=4)\n",
        "pipe_svc_clf.fit(X_train, Y_train)\n",
        "#3hr 20mins"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "636WkzQVZKdS",
        "outputId": "394bbb79-644e-44dc-a9c9-7b3d5572edc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                             ('svc',\n",
              "                                              SVC(class_weight='balanced',\n",
              "                                                  kernel='linear',\n",
              "                                                  probability=True))]),\n",
              "                   n_iter=4, n_jobs=2,\n",
              "                   param_distributions={'svc__C': array([0.2 , 0.35, 0.5 , 0.65, 0.8 , 0.95]),\n",
              "                                        'tfidf__max_df': [0.5],\n",
              "                                        'tfidf__min_df': [5],\n",
              "                                        'tfidf__ngram_range': [(1, 3)]},\n",
              "                   scoring='roc_auc')"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = id\n",
        "\n",
        "submission['label'] = pipe_svc_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('SVM1_.csv', index=False)"
      ],
      "metadata": {
        "id": "7Unx1yjLmPGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.83737\n",
        "Private score: 0.83891"
      ],
      "metadata": {
        "id": "3ocOaC7LpdfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that SVM performs the best for nlp tasks now in the next step we will add some parameters to search for the best of them"
      ],
      "metadata": {
        "id": "-6UEMvtLziOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Char n-gram"
      ],
      "metadata": {
        "id": "xh6xux72z-5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# # feature creation and modelling in a single function\n",
        "# pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"svc\", SVC(class_weight='balanced', kernel='linear',probability=True,))])\n",
        "\n",
        "# # define parameter space to test # runtime 19min\n",
        "# params = {\n",
        "#     \"tfidf__ngram_range\": [(1, 3)],\n",
        "#     \"tfidf__max_df\": [0.5],\n",
        "#     \"tfidf__min_df\": [5],\n",
        "#     \"tfidf__analyzer\":[\"char\"],\n",
        "     \n",
        "#     \"svc__C\": np.arange(0.2, 1, 0.15),\n",
        "# }\n",
        "# pipe_svc_clf = RandomizedSearchCV(pipe, params, n_jobs=2, scoring=\"roc_auc\",  cv=pds, n_iter=4)\n",
        "# pipe_svc_clf.fit(X_train, Y_train)\n",
        "# very Long computational time "
      ],
      "metadata": {
        "id": "In_KinAyq6dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# submission = pd.DataFrame()\n",
        "\n",
        "# submission['id'] = id\n",
        "\n",
        "# submission['label'] = pipe_svc_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "# submission.to_csv('SVM2_.csv', index=False)"
      ],
      "metadata": {
        "id": "4JGpMVF4sUQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature creation and modelling in a single function\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "pipe = Pipeline(\n",
        "    [\n",
        "                 (\"tfidf\", TfidfVectorizer()), \n",
        "                 (\"log\", LogisticRegression())])\n",
        "                 \n",
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "    \"tfidf__analyzer\":[\"char\"],\n",
        "       \n",
        " \n",
        "}\n",
        "# it is quite slow so we do 4 for now\n",
        "pipe_clf =RandomizedSearchCV(pipe, params, n_jobs=2, scoring=\"roc_auc\",  cv=pds, n_iter=4)\n",
        "pipe_clf.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UflHdFQkKTpo",
        "outputId": "17b0bfad-8e9f-4c96-83f2-bc9c743a0180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                             ('log', LogisticRegression())]),\n",
              "                   n_iter=4, n_jobs=2,\n",
              "                   param_distributions={'tfidf__analyzer': ['char'],\n",
              "                                        'tfidf__max_df': array([0.3]),\n",
              "                                        'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        'tfidf__ngram_range': [(1, 2), (1, 3)]},\n",
              "                   scoring='roc_auc')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = id\n",
        "\n",
        "submission['label'] = pipe_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('log2_.csv', index=False)"
      ],
      "metadata": {
        "id": "uvU4KR2IK9cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.78521\n",
        "Public score: 0.78176\n"
      ],
      "metadata": {
        "id": "C--8usG8LVg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that char n-gram doesn't gives us the best performance so we will continue using word n-gram whic is the defult"
      ],
      "metadata": {
        "id": "DJZ0QB2H0Hvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Different preprocessing using embedding"
      ],
      "metadata": {
        "id": "TEurs69VQta3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "#Choosing the steemmer language english\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stop_words = set(stopwords.words(\"english\")) #stopwords\n",
        "\n",
        "\n",
        "def clean_text(text, for_embedding=True):\n",
        "    \"\"\" steps:\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "    \"\"\"\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-z√Ä-≈æ ]\", re.IGNORECASE)\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z√Ä-≈æ]\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        RE_ASCII = re.compile(r\"[^A-Za-z√Ä-≈æ,.!? ]\", re.IGNORECASE)\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z√Ä-≈æ,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text)\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    if for_embedding:\n",
        "        # no stemming, lowering and punctuation / stop words removal\n",
        "        words_filtered = word_tokens\n",
        "    else:\n",
        "        words_filtered = [\n",
        "# Apply stemming to convert tokens to their root form. This is a rule-based process of word form conversion where word-suffixes are truncated irrespective of whether the root word is an actual word in the language dictionary.\n",
        "        \n",
        "            stemmer.stem(word) for word in words_tokens_lower if word not in stop_words \n",
        "            \n",
        "            ]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWC9gr-GQsPf",
        "outputId": "8e38b620-f170-4233-f93a-907ea5340769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean texts for train dataset\n",
        "data[\"text_clean\"] = data.loc[data[\"text\"].str.len() > 20, \"text\"]\n",
        "data[\"text_clean\"] = data[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x, for_embedding=True) if isinstance(x, str) else x\n",
        ")\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yYn4p8DSQ9hw",
        "outputId": "7797bd96-a4c3-48f8-ee94-50e83a4b3e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                      text  \\\n",
              "0      A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1      British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2      In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3      Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4      Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                    ...   \n",
              "59753                Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion of Finland by the USSR (1939, colorized)   \n",
              "59754                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "59755                Is It Safe To Smoke Marijuana During Pregnancy? YouÈà•Ê™á Be Surprised Of The Answer | no   \n",
              "59756                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "59757                Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "       label  \\\n",
              "0          0   \n",
              "1          0   \n",
              "2          0   \n",
              "3          0   \n",
              "4          0   \n",
              "...      ...   \n",
              "59753      0   \n",
              "59754      1   \n",
              "59755      0   \n",
              "59756      0   \n",
              "59757      1   \n",
              "\n",
              "                                                                                                text_clean  \n",
              "0      group of friends began to volunteer at homeless shelter after their neighbors protested . Seeing...  \n",
              "1      British Prime Minister Theresa May on Nerve Attack on Former Russian Spy The government has conc...  \n",
              "2      In , Goodyear released kit that allows PS to be brought to heel . https youtube com watch ALXulk...  \n",
              "3      Happy Birthday , Bob Barker ! The Price Is Right Host on How He Like to Be Remembered As the man...  \n",
              "4      Obama to Nation Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Johns...  \n",
              "...                                                                                                    ...  \n",
              "59753                         Finish Sniper Simo yh during the invasion of Finland by the USSR , colorized  \n",
              "59754                           Nigerian Prince Scam took from Kansas man years later , he getting it back  \n",
              "59755                   Is It Safe To Smoke Marijuana During Pregnancy ? You Be Surprised Of The Answer no  \n",
              "59756                       Julius Caesar upon realizing that everyone in the room has knife except him bc  \n",
              "59757                  Jeff Bridges Releasing leeping Tapes , ? New Album Designed to Help You Fall Asleep  \n",
              "\n",
              "[59758 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-700cd825-8bb4-470f-8edc-3cdf99de276e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "      <td>group of friends began to volunteer at homeless shelter after their neighbors protested . Seeing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "      <td>British Prime Minister Theresa May on Nerve Attack on Former Russian Spy The government has conc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "      <td>In , Goodyear released kit that allows PS to be brought to heel . https youtube com watch ALXulk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Happy Birthday , Bob Barker ! The Price Is Right Host on How He Like to Be Remembered As the man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "      <td>Obama to Nation Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Johns...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59753</th>\n",
              "      <td>Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "      <td>Finish Sniper Simo yh during the invasion of Finland by the USSR , colorized</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59754</th>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "      <td>Nigerian Prince Scam took from Kansas man years later , he getting it back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59755</th>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? YouÈà•Ê™á Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy ? You Be Surprised Of The Answer no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59756</th>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has knife except him bc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59757</th>\n",
              "      <td>Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "      <td>Jeff Bridges Releasing leeping Tapes , ? New Album Designed to Help You Fall Asleep</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59758 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-700cd825-8bb4-470f-8edc-3cdf99de276e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-700cd825-8bb4-470f-8edc-3cdf99de276e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-700cd825-8bb4-470f-8edc-3cdf99de276e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Clean texts for test data\n",
        "data1[\"text_clean\"] = data1.loc[data1[\"text\"].str.len() > 0, \"text\"]\n",
        "data1[\"text_clean\"] = data1[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x, for_embedding=True) if isinstance(x, str) else x\n",
        ")\n",
        "data1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "VnmzrhQ5RySQ",
        "outputId": "6c42829e-975d-44be-d43b-785c0555095b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                  text  \\\n",
              "0                                                                           stargazer    \n",
              "1                                                                                 yeah   \n",
              "2                           PD: Phoenix car thief gets instructions from YouTube video   \n",
              "3                       As Trump Accuses Iran, He Has One Problem: His Own Credibility   \n",
              "4                                                         \"Believers\" - Hezbollah 2011   \n",
              "...                                                                                ...   \n",
              "59146                                                Bicycle taxi drivers of New Delhi   \n",
              "59147                             Trump blows up GOP's formula for winning House races   \n",
              "59148  Napoleon returns from his exile on the island of Elba. (March 1815), Colourised   \n",
              "59149                                 Deep down he always wanted to be a ballet dancer   \n",
              "59150                        Toddler miraculously survives 6-story fall landing on car   \n",
              "\n",
              "                                                                       text_clean  \n",
              "0                                                                       stargazer  \n",
              "1                                                                            yeah  \n",
              "2                       PD Phoenix car thief gets instructions from YouTube video  \n",
              "3                  As Trump Accuses Iran , He Has One Problem His Own Credibility  \n",
              "4                                                             Believers Hezbollah  \n",
              "...                                                                           ...  \n",
              "59146                                           Bicycle taxi drivers of New Delhi  \n",
              "59147                          Trump blows up GOP formula for winning House races  \n",
              "59148  Napoleon returns from his exile on the island of Elba . March , Colourised  \n",
              "59149                              Deep down he always wanted to be ballet dancer  \n",
              "59150                     Toddler miraculously survives story fall landing on car  \n",
              "\n",
              "[59151 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73951a20-afa8-4447-83ab-4aaf79889efb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stargazer</td>\n",
              "      <td>stargazer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yeah</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "      <td>PD Phoenix car thief gets instructions from YouTube video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
              "      <td>As Trump Accuses Iran , He Has One Problem His Own Credibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "      <td>Believers Hezbollah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>Trump blows up GOP's formula for winning House races</td>\n",
              "      <td>Trump blows up GOP formula for winning House races</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>Napoleon returns from his exile on the island of Elba. (March 1815), Colourised</td>\n",
              "      <td>Napoleon returns from his exile on the island of Elba . March , Colourised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "      <td>Deep down he always wanted to be ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>Toddler miraculously survives 6-story fall landing on car</td>\n",
              "      <td>Toddler miraculously survives story fall landing on car</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73951a20-afa8-4447-83ab-4aaf79889efb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73951a20-afa8-4447-83ab-4aaf79889efb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73951a20-afa8-4447-83ab-4aaf79889efb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop when any of x missing\n",
        "data = data[(data[\"text_clean\"] != \"\") & (data[\"text_clean\"] != \"null\")]\n",
        "\n",
        "data = data.dropna(axis=\"index\", ).reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "KPkEZPvCSABS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting X train and y actual and X test\n",
        "\n",
        "X_train = data[\"text_clean\"]\n",
        "Y_train = data[\"label\"]\n",
        "X_test = data1[\"text_clean\"]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfqfrWrwSQc5",
        "outputId": "8e4f0dd0-759e-404e-c2bd-d07258de2cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(59758,)\n",
            "(59151,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "\n",
        "\n",
        "# Further split the original training set to a train and a validation set\n",
        "X_train2, X_val, y_train2, y_val = train_test_split(\n",
        "    X_train, Y_train, train_size = 0.7, stratify = Y_train, random_state = 3800)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in X_train2.index else 0 for x in X_train.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)"
      ],
      "metadata": {
        "id": "89QGw97IravC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline(\n",
        "    [\n",
        "                 (\"tfidf\", TfidfVectorizer()), \n",
        "                 (\"LOG\", LogisticRegression())])\n",
        "                 \n",
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "    #  'svc__n_estimators': [20, 30, 40],  \n",
        "    #  my_classifier__n_estimators points to my_classifier->n_estimators \n",
        "    # 'svc__penalty':['none', 'l1', 'l2', 'elasticnet']  ,    \n",
        "    # 'svc__solver' :['newton-cg', 'lbfgs', 'liblinear'],\n",
        "    # 'svc__C' :  [1e-5, 100]\n",
        "}\n",
        "pipe_clf5 =RandomizedSearchCV(\n",
        "    pipe, params, n_jobs=2, scoring=\"roc_auc\", cv=pds, n_iter=5)\n",
        "pipe_clf5.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK2nTVwTSSdI",
        "outputId": "305a5968-643e-46ed-b904-5e974991b64b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                             ('LOG', LogisticRegression())]),\n",
              "                   n_iter=5, n_jobs=2,\n",
              "                   param_distributions={'tfidf__max_df': array([0.3]),\n",
              "                                        'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        'tfidf__ngram_range': [(1, 2), (1, 3)]},\n",
              "                   scoring='roc_auc')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = id\n",
        "\n",
        "submission['label'] =pipe_clf5.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('log5_.csv', index=False)"
      ],
      "metadata": {
        "id": "jTd1eJwOSu8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Score: 0.85219\n",
        "Public score: 0.85469"
      ],
      "metadata": {
        "id": "xWiGNZpQTKFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our observation we can see that embedding  gives us the optimal performance. Embeddings make it easier to do machine learning on large inputs like sparse vectors representing words. Ideally, an embedding captures some of the semantics of the input by placing semantically similar inputs close together in the embedding space."
      ],
      "metadata": {
        "id": "D1alsKus0chn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will try performing embedding on our optimal model which is SVM"
      ],
      "metadata": {
        "id": "SFFkvlGO0znG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "5122e6ab-79e3-425e-f366-7f1fefd34faf",
        "id": "l06r0B00yRz0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                             ('svc',\n",
              "                                              SVC(class_weight='balanced',\n",
              "                                                  kernel='linear',\n",
              "                                                  probability=True))]),\n",
              "                   n_iter=4, n_jobs=2,\n",
              "                   param_distributions={'svc__C': array([0.2 , 0.35, 0.5 , 0.65, 0.8 , 0.95]),\n",
              "                                        'tfidf__max_df': [0.5],\n",
              "                                        'tfidf__min_df': [5],\n",
              "                                        'tfidf__ngram_range': [(1, 3)]},\n",
              "                   scoring='roc_auc')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "pipe = Pipeline(\n",
        "    [\n",
        "                 (\"tfidf\", TfidfVectorizer()), \n",
        "                 (\"svc\", SVC(class_weight='balanced', kernel='linear',probability=True,))\n",
        "                 ]\n",
        "                )\n",
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 3)],\n",
        "    \"tfidf__max_df\": [0.5],\n",
        "    \"tfidf__min_df\": [5],\n",
        "    \"svc__C\": np.arange(0.2, 1, 0.15),\n",
        "}\n",
        "pipe_svc_clf6 = RandomizedSearchCV(pipe, params, n_jobs=2, scoring=\"roc_auc\",  cv=pds, n_iter=4)\n",
        "pipe_svc_clf6.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9r8brTAyRz7"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = id\n",
        "\n",
        "submission['label'] =pipe_svc_clf6.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('svm5_.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ki-Lydnx66u"
      },
      "source": [
        "Score: 0.86339\n",
        "Public score: 0.86436"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can the this is the optimal solution that gives us the best performance"
      ],
      "metadata": {
        "id": "M0AGkymr2TPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "In this project we applied the a workflow for natural language processing with the goal to predict. After applying a pre processing and cleaning strategy, we have used a frequency based method (`TF-IDF`) to transform input texts to a numeric representation. These text vectors are the features used as input in our classification models. In the next step, we applied different models to our classification task and compared the results using a meaningful prediction and compared their scores. We've learned that this rather simple process is able to already produce decent results. Following, we have performed parameter tuning to further improve our model performance. \n",
        "In the next post, we will improve upon the outcome of this process. For that, we will apply more advanced methods. For one, this will include hyprid models. Moreover, we will use different, advanced implementations of Neural Networks as our classification models."
      ],
      "metadata": {
        "id": "moiugMyf1fAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimal model ‚òë\n",
        "SVM\n",
        "using embeeding and word-ngram"
      ],
      "metadata": {
        "id": "zPrnIxoN2OmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion (Questions & Answers) üß†‚ùì\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uQQA_LFXMZ3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üåà What is the difference between Character n-gram and Word n-gram? Which one tends to suffer more from the OOV issue?\n",
        "An N-gram means a sequence of N words. N-grams are like a sliding window that moves across the word - a continuous sequence of characters of the specified length. Character N-Grams splits each word based on characters but word N-Grams splits the text based on words. Out-of-vocabulary (OOV) are terms that are not part of the normal lexicon found in a natural language processing environment.\n",
        "Word n-gram tends to suffer more from OOV (Out-Of-Vocabulary) issue because of the new words that is presented in test dataset and doesn't exist in train dataset\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### üåà What is the difference between stop word removal and stemming? Are these techniques language-dependent?\n",
        "Stop word elimination and stemming are commonly used method in indexing. Stop words are high frequency words that have little semantic weight and are thus unlikely to help the retrieval process. Stemming conflates morphological variants of words in its root or stem.\n",
        "These techniques are language dependant\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### üåà Is tokenization techniques language dependent? Why?\n",
        "Tokenization is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms\n",
        "it is language dependent as it should know the meaning of each single word to split it depend on language.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### üåà What is the difference between count vectorizer and tf-idf vectorizer? Would it be feasible to use all possible n-grams? If not, how should you select them?\n",
        "- The main difference between them is that TfidfVectorizer performs both term frequency and inverse document frequency for you, while using TfidfTransformer will require you to use the CountVectorizer class from Scikit-Learn to perform Term Frequency. \n",
        "-It isn't feasible to use all possible n-grams\n",
        "- We select based on the problem an important parameter that needs explanation is the ngram_range. An ngram of one means that you look at each word separately. An ngram of two (or bigram) means that you take the preceding and following word into account as well. In sentiment Analysis, setting n-gram ranges that use bigrams or trigrams can make great difference in the accuracy of classification,as they can capture more complex expressions formed by the composition of morethan one word. \n",
        "---"
      ],
      "metadata": {
        "id": "_lPGUnmmDWYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "https://link.springer.com/content/pdf/10.1007/978-81-8489-203-1_31.pdf\n",
        "https://en.wikipedia.org/wiki/N-gram#:~:text=Out%2Dof%2Dvocabulary%20words,-Main%20article%3A%20Statistical&text=An%20issue%20when%20using%20n,or%20database%20during%20its%20preparation.\n",
        "https://blog.marketmuse.com/glossary/word-vectors-definition/\n",
        "https://blog.marketmuse.com/glossary/out-of-vocabulary-oov-definition/#:~:text=Out%2Dof%2Dvocabulary%20OOV,mathematical%20equivalent%20of%20word%20meaning\n",
        "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-ngram-tokenizer.html\n",
        "https://www.analyticsvidhya.com/blog/2021/09/what-are-n-grams-and-how-to-implement-them-in-python/\n",
        "https://towardsdatascience.com/understanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058#:~:text=An%20N%2Dgram%20means%20a,grams%2C%20which%20is%20quite%20interesting.\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "https://github.com/Shubha23/Text-processing-NLP/blob/mas\n",
        "ter/NLP%20-%20Text%20processing%20pipeline.ipynb\n",
        "https://itechindia.co/blog/which-of-the-3-algorithms-models-should-you-choose-for-sentiment-analysis-2/\n",
        "https://towardsdatascience.com/tf-idf-explained-and-python-sklearn-implementation-b020c5e83275"
      ],
      "metadata": {
        "id": "ycmZy_NwKZ2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture\n",
        "https://gate.ac.uk/sale/nle-svm/svm-ie.pdf\n",
        "https://monkeylearn.com/text-classification-support-vector-machines-svm/#:~:text=From%20Texts%20to%20Vectors,encode%20any%20kind%20of%20data.\n",
        "https://neptune.ai/blog/xgboost-everything-you-need-to-know"
      ],
      "metadata": {
        "id": "YqfjdNgJ2tWE"
      }
    }
  ]
}